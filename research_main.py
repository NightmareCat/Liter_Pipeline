
from pathlib import Path
from datetime import datetime
# import os
import questionary
from log_init import setup_logger 
from research_pipeline.research_long_analyse import summarize_all_documents
from research_pipeline.search_similar_papers import search_similar
from research_pipeline.submit_summary_to_qwen import submit_summary_to_qwen
from research_pipeline.submit_summary_to_deepseek import submit_summary_to_deepseek

database_dir = "embedding_qwen_long"   #é€‰æ‹©ä½¿ç”¨çš„äºŒçº§å¤„ç†æ–‡çŒ®åº“
Research_object = 'åœ¨å«æ˜Ÿé€šä¿¡ç³»ç»Ÿä¸­çš„ä¿¡å·å¤„ç†ä¼˜åŒ–æ–¹æ¡ˆ' 
top_k = 10   #æ‰¾åˆ°nç¯‡æœ€ç›¸å…³æ–‡ç« 
summary_model = 2 #1-qwen 2-deepseek

logger = setup_logger(__name__)  # åˆå§‹åŒ–logä¿¡æ¯

def research_sel():
    scored = search_similar(Research_object, database_dir, top_k)

    print(f"\nğŸ” æ­£åœ¨åŒ¹é…è¯¾é¢˜æ–¹å‘ï¼š{Research_object}\n")
    print(f"ğŸ“„ Top {len(scored)} æœ€ç›¸å…³è®ºæ–‡ï¼š\n")
    for idx, item in enumerate(scored, 1):
        print(f"{idx}. ğŸ“ {item['document']}  (åŒ¹é…åº¦: {item['similarity']:.4f})")
        print(f"- æœ€ç›¸å…³æ®µè½:\n\n  {item['best_paragraph'][:180]}...\n")
        
        
    document_list = [item["document"] for item in scored]

    # åˆ›å»ºå¤šé€‰æ¡†ï¼Œé»˜è®¤å…¨é€‰
    selected = questionary.checkbox(
        "è¯·é€‰æ‹©éœ€è¦è¿›ä¸€æ­¥åˆ†æçš„æ–‡æ¡£ï¼ˆç©ºæ ¼é€‰æ‹©ï¼Œå›è½¦ç¡®è®¤ï¼‰:",
        choices=[{"name": doc, "checked": True} for doc in document_list]
    ).ask()  # .ask() æ‰§è¡Œäº¤äº’

    print("ä½ é€‰æ‹©äº†:")
    for item in selected:
        print(item)

    return selected

def divideMD(selected, Research_object_tmp):
    # è¾“å‡ºç›®å½•ï¼šresearch_output/20250521
    today = datetime.today().strftime("%m%d-%H%M")
    output_root = Path("research_output") / (today + Research_object_tmp)
    output_root.mkdir(parents=True, exist_ok=True)
    
    pdf_directory = Path("liter_source")
    
    summarize_all_documents(selected, pdf_directory, output_dir = output_root, R_object =  Research_object_tmp, max_workers = 10)
        
    return  output_root

def summarize_folder_to_report(folder_path: Path, research_topic: str):
    """
    éå†æŒ‡å®šæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰ Markdown æ–‡ä»¶ï¼Œç”Ÿæˆä¸€ç¯‡ç»¼åˆè°ƒç ”æŠ¥å‘Šã€‚

    Args:
        folder_path (Path): åŒ…å« .md æ–‡ä»¶çš„ç›®å½•è·¯å¾„ï¼ˆPathç±»å‹ï¼‰
        research_topic (str): è°ƒç ”ä¸»é¢˜
    """
    if not folder_path.exists() or not folder_path.is_dir():
        logger.error(f"âŒ è·¯å¾„ä¸å­˜åœ¨æˆ–ä¸æ˜¯æ–‡ä»¶å¤¹: {folder_path}")
        return

    md_files = sorted(folder_path.glob("*.md"))
    if not md_files:
        logger.error("âš ï¸ æœªæ‰¾åˆ°ä»»ä½• Markdown æ–‡ä»¶ã€‚")
        return
    
    logger.info(f"ğŸ“„ å·²è¯»å– Markdown æ–‡ä»¶ {len(md_files)} ä¸ªã€‚")

    # è¯»å–æ‰€æœ‰ Markdown æ–‡ä»¶å†…å®¹
    markdown_contents = [f.read_text(encoding="utf-8") for f in md_files]

    # è°ƒç”¨ API ç”ŸæˆæŠ¥å‘Š
    if summary_model == 1:
        logger.info('æ­£åœ¨ä½¿ç”¨Qwen Maxæ¨¡å‹è¿›è¡Œæ€»ç»“')
        report = submit_summary_to_qwen(research_topic, markdown_contents)
        
    elif summary_model == 2:
        logger.info('æ­£åœ¨ä½¿ç”¨Deepseek v3æ¨¡å‹è¿›è¡Œæ€»ç»“')
        report = submit_summary_to_deepseek(research_topic, markdown_contents)
     
    report = report.replace("][", "] [")  #è§£å†³typoraçš„æ¸²æŸ“é—®é¢˜
   
    # è¾“å‡ºæŠ¥å‘Š
    output_path = folder_path / (research_topic+"â€”â€”ç»¼åˆè°ƒç ”æŠ¥å‘Š.md")
    output_path.write_text(report, encoding="utf-8")
    logger.info(f"âœ… æŠ¥å‘Šå·²ç”Ÿæˆï¼š{output_path}")
    

if __name__ == '__main__':

    process_trigger = 2
    if process_trigger == 1:
        selected = research_sel()   #æ‰¾åˆ°æœ€ç›¸å…³çš„Kç¯‡æ–‡ç« ï¼Œæ‰‹åŠ¨é€‰æ‹©å…¶ä¸­çš„Nç¯‡
        output_root = divideMD(selected,Research_object)   #å°†Nç¯‡æ–‡ç« è¾“å‡ºç»“æ„åŒ–ç»“æœ
    elif process_trigger == 2:
        output_root = Path('.\\research_output\\0527-1519åŸºäºOTFSæå‡ä¼ è¾“é€Ÿç‡')
        Research_object = "åŸºäºOTFSæå‡ä¼ è¾“é€Ÿç‡"
        
    summarize_folder_to_report(output_root , Research_object)